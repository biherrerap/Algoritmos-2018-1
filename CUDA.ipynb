{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gWwBsHKzDK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo CUDA AND NVIDIA INSTALLATION\n",
        "!echo NOTE: THERE IS A QUESTION IN THE INSTALLATION, PLEASE DO NOT FORGET TO ANSWER IT (YOU CAN CHOOSE Y)\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb;\n",
        "!dpkg -i cuda-repo-ubuntu1604_8.0.61-1_amd64.deb;\n",
        "!apt-get update -qq;\n",
        "!apt-get install cuda-8.0;\n",
        "!ln -sf /usr/local/cuda-8.0 /usr/local/cuda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02l44MvkzPWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['PATH'] += ':/usr/local/cuda/bin'\n",
        "os.environ['LD_LIBRARY_PATH'] += ':/usr/local/cuda/lib'\n",
        "\n",
        "!apt-get install gcc-5 g++-5 -y -qq;\n",
        "!ln -s /usr/bin/gcc-5 /usr/local/cuda/bin/gcc;\n",
        "!ln -s /usr/bin/g++-5 /usr/local/cuda/bin/g++;\n",
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n",
        "!clear"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqesLUnJ1g6s",
        "colab_type": "code",
        "outputId": "f24e144f-cf04-466a-fd3a-7f05cad7f872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "!echo NVIDIA CUDA AND DRIVES VERIFICATION\n",
        "%cd /usr/local/cuda/samples/1_Utilities/deviceQuery/\n",
        "!ls\n",
        "!make\n",
        "!./deviceQuery\n",
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA CUDA AND DRIVES VERIFICATION\n",
            "/usr/local/cuda-8.0/samples/1_Utilities/deviceQuery\n",
            "deviceQuery.cpp  Makefile  NsightEclipse.xml  readme.txt\n",
            "/usr/local/cuda-8.0/bin/nvcc -ccbin g++ -I../../common/inc  -m64    -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_60,code=compute_60 -o deviceQuery.o -c deviceQuery.cpp\n",
            "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "/usr/local/cuda-8.0/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_60,code=compute_60 -o deviceQuery deviceQuery.o \n",
            "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "mkdir -p ../../bin/x86_64/linux/release\n",
            "cp deviceQuery ../../bin/x86_64/linux/release\n",
            "./deviceQuery Starting...\n",
            "\n",
            " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
            "\n",
            "Detected 1 CUDA Capable device(s)\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  CUDA Driver Version / Runtime Version          10.0 / 8.0\n",
            "  CUDA Capability Major/Minor version number:    7.5\n",
            "  Total amount of global memory:                 15080 MBytes (15812263936 bytes)\n",
            "MapSMtoCores for SM 7.5 is undefined.  Default to use 128 Cores/SM\n",
            "MapSMtoCores for SM 7.5 is undefined.  Default to use 128 Cores/SM\n",
            "  (40) Multiprocessors, (128) CUDA Cores/MP:     5120 CUDA Cores\n",
            "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
            "  Memory Clock rate:                             5001 Mhz\n",
            "  Memory Bus Width:                              256-bit\n",
            "  L2 Cache Size:                                 4194304 bytes\n",
            "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
            "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
            "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Maximum number of threads per multiprocessor:  1024\n",
            "  Maximum number of threads per block:           1024\n",
            "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
            "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "  Texture alignment:                             512 bytes\n",
            "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
            "  Run time limit on kernels:                     No\n",
            "  Integrated GPU sharing Host Memory:            No\n",
            "  Support host page-locked memory mapping:       Yes\n",
            "  Alignment requirement for Surfaces:            Yes\n",
            "  Device has ECC support:                        Enabled\n",
            "  Device supports Unified Addressing (UVA):      Yes\n",
            "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
            "  Compute Mode:\n",
            "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
            "\n",
            "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = Tesla T4\n",
            "Result = PASS\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2016 NVIDIA Corporation\n",
            "Built on Tue_Jan_10_13:22:03_CST_2017\n",
            "Cuda compilation tools, release 8.0, V8.0.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNGKpuDH1ngJ",
        "colab_type": "code",
        "outputId": "0cf1f4c6-7777-484a-ffe8-0f663510e947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-aa48uqfm\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-aa48uqfm\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gww3zfst/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2eeKmMVdtt2",
        "colab_type": "code",
        "outputId": "7b635d97-121e-4286-b824-620056f13f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%reload_ext nvcc_plugin"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /usr/local/cuda-8.0/samples/1_Utilities/deviceQuery/src\n",
            "Out bin /usr/local/cuda-8.0/samples/1_Utilities/deviceQuery/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC56SD4W0QTO",
        "colab_type": "text"
      },
      "source": [
        "#La foto se tiene que subir a: \n",
        "/usr/local/cuda-8.0/samples/1_Utilities/deviceQuery\n",
        "\n",
        "Y el nombre de la foto se especifica en el programa, por ahora estoy usando la de 720p.png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyK7NsPTiSJT",
        "colab_type": "code",
        "outputId": "fd6df012-8d63-4a15-ae62-c1c79d509a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile main.cu\n",
        "\n",
        "#include <unistd.h>\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <stdarg.h>\n",
        "#include <vector>\n",
        "#include <cmath>\n",
        "#include <helper_cuda.h>\n",
        "#define PNG_DEBUG 3\n",
        "#include <png.h>\n",
        "\n",
        "using std::vector;\n",
        "\n",
        "typedef vector<double> Array;\n",
        "typedef vector<Array> Matrix;\n",
        "typedef vector<Matrix> Image;\n",
        "\n",
        "Matrix filter;\n",
        "Image image;\n",
        "Image newImage;\n",
        "int num_threads;\n",
        "\n",
        "void abort_(const char * s, ...)\n",
        "{\n",
        "        va_list args;\n",
        "        va_start(args, s);\n",
        "        vfprintf(stderr, s, args);\n",
        "        fprintf(stderr, \"\\n\");\n",
        "        va_end(args);\n",
        "        abort();\n",
        "}\n",
        "\n",
        "int GetDeviceCount(){\n",
        "    int deviceCount = 0;\n",
        "    cudaError_t error_id = cudaGetDeviceCount(&deviceCount);\n",
        "    return deviceCount;\n",
        "}\n",
        "\n",
        "int x, y;\n",
        "\n",
        "int width, height;\n",
        "png_byte color_type;\n",
        "png_byte bit_depth;\n",
        "\n",
        "png_structp png_ptr;\n",
        "png_infop info_ptr;\n",
        "int number_of_passes;\n",
        "png_bytep * row_pointers;\n",
        "\n",
        "void read_png_file(char* file_name)\n",
        "{\n",
        "        char header[8];    // 8 is the maximum size that can be checked\n",
        "\n",
        "        /* open file and test for it being a png */\n",
        "        FILE *fp = fopen(file_name, \"rb\");\n",
        "        if (!fp)\n",
        "                abort_(\"[read_png_file] File %s could not be opened for reading\", file_name);\n",
        "        fread(header, 1, 8, fp);\n",
        "        //if (png_sig_cmp(header, 0, 8))\n",
        "        //        abort_(\"[read_png_file] File %s is not recognized as a PNG file\", file_name);\n",
        "\n",
        "\n",
        "        /* initialize stuff */\n",
        "        png_ptr = png_create_read_struct(PNG_LIBPNG_VER_STRING, NULL, NULL, NULL);\n",
        "\n",
        "        if (!png_ptr)\n",
        "                abort_(\"[read_png_file] png_create_read_struct failed\");\n",
        "\n",
        "        info_ptr = png_create_info_struct(png_ptr);\n",
        "        if (!info_ptr)\n",
        "                abort_(\"[read_png_file] png_create_info_struct failed\");\n",
        "\n",
        "        if (setjmp(png_jmpbuf(png_ptr)))\n",
        "                abort_(\"[read_png_file] Error during init_io\");\n",
        "\n",
        "        png_init_io(png_ptr, fp);\n",
        "        png_set_sig_bytes(png_ptr, 8);\n",
        "\n",
        "        png_read_info(png_ptr, info_ptr);\n",
        "\n",
        "        width = png_get_image_width(png_ptr, info_ptr);\n",
        "        height = png_get_image_height(png_ptr, info_ptr);\n",
        "        color_type = png_get_color_type(png_ptr, info_ptr);\n",
        "        bit_depth = png_get_bit_depth(png_ptr, info_ptr);\n",
        "\n",
        "        number_of_passes = png_set_interlace_handling(png_ptr);\n",
        "        png_read_update_info(png_ptr, info_ptr);\n",
        "\n",
        "\n",
        "        /* read file */\n",
        "        if (setjmp(png_jmpbuf(png_ptr)))\n",
        "                abort_(\"[read_png_file] Error during read_image\");\n",
        "\n",
        "        row_pointers = (png_bytep*) malloc(sizeof(png_bytep) * height);\n",
        "        for (y=0; y<height; y++)\n",
        "                row_pointers[y] = (png_byte*) malloc(png_get_rowbytes(png_ptr,info_ptr));\n",
        "\n",
        "        png_read_image(png_ptr, row_pointers);\n",
        "\n",
        "        fclose(fp);\n",
        "}\n",
        "\n",
        "\n",
        "void write_png_file(char* file_name)\n",
        "{\n",
        "        /* create file */\n",
        "        FILE *fp = fopen(file_name, \"wb\");\n",
        "        if (!fp)\n",
        "                abort_(\"[write_png_file] File %s could not be opened for writing\", file_name);\n",
        "\n",
        "\n",
        "        /* initialize stuff */\n",
        "        png_ptr = png_create_write_struct(PNG_LIBPNG_VER_STRING, NULL, NULL, NULL);\n",
        "\n",
        "        if (!png_ptr)\n",
        "                abort_(\"[write_png_file] png_create_write_struct failed\");\n",
        "\n",
        "        info_ptr = png_create_info_struct(png_ptr);\n",
        "        if (!info_ptr)\n",
        "                abort_(\"[write_png_file] png_create_info_struct failed\");\n",
        "\n",
        "        if (setjmp(png_jmpbuf(png_ptr)))\n",
        "                abort_(\"[write_png_file] Error during init_io\");\n",
        "\n",
        "        png_init_io(png_ptr, fp);\n",
        "\n",
        "\n",
        "        /* write header */\n",
        "        if (setjmp(png_jmpbuf(png_ptr)))\n",
        "                abort_(\"[write_png_file] Error during writing header\");\n",
        "\n",
        "        png_set_IHDR(png_ptr, info_ptr, width, height,\n",
        "                     bit_depth, color_type, PNG_INTERLACE_NONE,\n",
        "                     PNG_COMPRESSION_TYPE_BASE, PNG_FILTER_TYPE_BASE);\n",
        "\n",
        "        png_write_info(png_ptr, info_ptr);\n",
        "\n",
        "\n",
        "        /* write bytes */\n",
        "        if (setjmp(png_jmpbuf(png_ptr)))\n",
        "                abort_(\"[write_png_file] Error during writing bytes\");\n",
        "\n",
        "        png_write_image(png_ptr, row_pointers);\n",
        "\n",
        "\n",
        "        /* end write */\n",
        "        if (setjmp(png_jmpbuf(png_ptr)))\n",
        "                abort_(\"[write_png_file] Error during end of write\");\n",
        "\n",
        "        png_write_end(png_ptr, NULL);\n",
        "\n",
        "        /* cleanup heap allocation */\n",
        "        for (y=0; y<height; y++)\n",
        "                free(row_pointers[y]);\n",
        "        free(row_pointers);\n",
        "\n",
        "        fclose(fp);\n",
        "}\n",
        "\n",
        "Matrix getGaussian(int height, int width, double sigma)\n",
        "{\n",
        "    Matrix kernel(height, Array(width));\n",
        "    double sum=0.0;\n",
        "    int i,j;\n",
        "\n",
        "    for (i=0 ; i<height ; i++) {\n",
        "        for (j=0 ; j<width ; j++) {\n",
        "            kernel[i][j] = exp(-(i*i+j*j)/(2*sigma*sigma))/(2*M_PI*sigma*sigma);\n",
        "            sum += kernel[i][j];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for (i=0 ; i<height ; i++) {\n",
        "        for (j=0 ; j<width ; j++) {\n",
        "            kernel[i][j] /= sum;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return kernel;\n",
        "}\n",
        "\n",
        "__global__ void vectorAdd(double *image_d1, double *kernel, double *output, int width, int height, int kernelSize, int totalThreads)\n",
        "{\n",
        "    int id = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    //printf(\"blockDim is: %d blockId is: %d threadId is: %d id is: %d\\n\", blockDim.x, blockIdx.x, threadIdx.x, id);\n",
        "    //printf(\"width: %d height: %d id is: %d\\n\", width, height, id);\n",
        "\n",
        "    int filterHeight = kernelSize;\n",
        "    int filterWidth = kernelSize;\n",
        "    int newImageHeight = height-kernelSize+1;\n",
        "    //int newImageHeight = height;\n",
        "    int newImageWidth = width-kernelSize+1;\n",
        "    int d,i,j,h,w;\n",
        "    \n",
        "    int fromY = (newImageHeight / totalThreads)*id;\n",
        "    int toY = id != totalThreads-1 ? fromY + (newImageHeight / totalThreads) : newImageHeight;\n",
        "    \n",
        "    int fromX = (newImageWidth / totalThreads)*id;\n",
        "    int toX = id != totalThreads-1 ? fromX + (newImageWidth / totalThreads) : newImageWidth;\n",
        "    \n",
        "    //printf(\"I go from: %d to: %d \\n\", from, to);\n",
        "    \n",
        "    int numElements = sizeof(double) * 4 * newImageHeight * newImageWidth;\n",
        "        \n",
        "    for (i=0; i<newImageHeight ; i++) {\n",
        "        for (j=fromX ; j<toX ; j++) {\n",
        "            for(int k=0; k<4; k++){\n",
        "                output[i*newImageWidth*4 + j*4 + k] = 0;\n",
        "                for (h=i ; h<i+filterHeight ; h++) {\n",
        "                    for (w=j ; w<j+filterWidth ; w++) {\n",
        "                        output[i*newImageWidth*4 + j*4 + k] += kernel[(h-i) * kernelSize + (w-j)]*image_d1[h*width*4 + w*4 + k];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    printf(\"\");\n",
        "}\n",
        "\n",
        "\n",
        "void process_file(int kernel,int blocks,int threads)\n",
        "{\n",
        "    if (png_get_color_type(png_ptr, info_ptr) == PNG_COLOR_TYPE_RGB)\n",
        "      abort_(\"[process_file] input file is PNG_COLOR_TYPE_RGB but must be PNG_COLOR_TYPE_RGBA \"\n",
        "        \"(lacks the alpha channel)\");\n",
        "\n",
        "    if (png_get_color_type(png_ptr, info_ptr) != PNG_COLOR_TYPE_RGBA)\n",
        "      abort_(\"[process_file] color_type of input file must be PNG_COLOR_TYPE_RGBA (%d) (is %d)\",\n",
        "        PNG_COLOR_TYPE_RGBA, png_get_color_type(png_ptr, info_ptr));\n",
        "    \n",
        "    int device;\n",
        "    cudaGetDeviceCount(&device);\n",
        "    cudaSetDevice(device);\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, device);\n",
        "    \n",
        "    int err;\n",
        "    \n",
        "    int multiprocessorNum =  deviceProp.multiProcessorCount;\n",
        "    int cores_mp = _ConvertSMVer2Cores(deviceProp.major, deviceProp.minor);\n",
        "    int cores = _ConvertSMVer2Cores(deviceProp.major, deviceProp.minor) *deviceProp.multiProcessorCount;\n",
        "    int newWidth = (width-kernel + 1);\n",
        "    int newHeight = (height-kernel + 1);\n",
        "    \n",
        "    int size = sizeof(double) * 4 * width * height;\n",
        "    int kernelSize = sizeof(double) * kernel * kernel;\n",
        "    int outputSize = sizeof(double) * 4 * newHeight * newWidth;\n",
        "    \n",
        "    double *image_h1 = (double *)malloc(size);\n",
        "    double *image_d1 = NULL;\n",
        "    err = cudaMalloc((void **)&image_d1, size);\n",
        "    double *kernel_h1 = (double *)malloc(kernelSize);\n",
        "    double *kernel_d1 = NULL;\n",
        "    err = cudaMalloc(&kernel_d1, kernelSize);\n",
        "\n",
        "    double *output_h = (double *)malloc(outputSize);\n",
        "    double *output_d = NULL;\n",
        "    err = cudaMalloc((void **)&output_d, outputSize);\n",
        "   \n",
        "    // Initialize the HOST image\n",
        "    for (y=0; y<height; y++) {\n",
        "        png_byte* row = row_pointers[y];\n",
        "        for (x=0; x<width; x++) {   \n",
        "            png_byte* ptr = &(row[x*4]);\n",
        "            for(int i=0; i<4; i++){\n",
        "                image_h1[y*width*4 + x*4 + i] = (double)ptr[i];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    // Copy the HOST image to DEVICE image\n",
        "    err = cudaMemcpy(image_d1, image_h1, size, cudaMemcpyHostToDevice);\n",
        "    \n",
        "    Matrix filter = getGaussian(kernel, kernel, 10.0);\n",
        "    kernel_h1 = new double[kernel];\n",
        "    for(int i=0; i<kernel; i++){\n",
        "        for(int j=0; j<kernel; j++){ \n",
        "            kernel_h1[i*kernel + j] = filter[i][j];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    err = cudaMemcpy(kernel_d1, kernel_h1, kernelSize, cudaMemcpyHostToDevice);\n",
        "    \n",
        "    // vectorAdd<<<multiprocessorNum, cores_mp>>>(image_d1, kernel_d1, output_d, width, height, kernel);\n",
        "    vectorAdd<<<blocks, threads>>>(image_d1, kernel_d1, output_d, width, height, kernel, blocks*threads);\n",
        "    \n",
        "    err = cudaMemcpy(image_h1, image_d1, size, cudaMemcpyDeviceToHost);\n",
        "    err = cudaMemcpy(output_h, output_d, outputSize, cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    for (y=0; y<newHeight; y++) {\n",
        "        png_byte* row = row_pointers[y];\n",
        "        for (x=0; x<newWidth; x++) {   \n",
        "            png_byte* ptr = &(row[x*4]);\n",
        "            for(int i=0; i<4; i++){\n",
        "                 ptr[i] = output_h[y*newWidth*4 + x*4 + i];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    if (argc != 6)\n",
        "      abort_(\"Usage: program_name <file_in> <file_out> <kernel size> <blocks number> <threads number>\");\n",
        "    \n",
        "    int kernel = atoi(argv[3]);\n",
        "    int blocks = atoi(argv[4]);\n",
        "    int threads = atoi(argv[5]);\n",
        "    \n",
        "  \tread_png_file(argv[1]);\n",
        "    process_file(kernel, blocks, threads);\n",
        "    write_png_file(argv[2]);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting main.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn-MFa-XiYP8",
        "colab_type": "code",
        "outputId": "423db395-e71a-47da-c534-ea3071d19181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "!nvcc main.cu -o main -I /usr/local/cuda/samples/common/inc -lpng"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "main.cu(194): warning: variable \"d\" was declared but never referenced\n",
            "\n",
            "main.cu(197): warning: variable \"toY\" was declared but never referenced\n",
            "\n",
            "main.cu(204): warning: variable \"numElements\" was declared but never referenced\n",
            "\n",
            "main.cu(239): warning: variable \"err\" was set but never used\n",
            "\n",
            "main.cu(241): warning: variable \"multiprocessorNum\" was declared but never referenced\n",
            "\n",
            "main.cu(194): warning: variable \"d\" was declared but never referenced\n",
            "\n",
            "main.cu(197): warning: variable \"toY\" was declared but never referenced\n",
            "\n",
            "main.cu(204): warning: variable \"numElements\" was declared but never referenced\n",
            "\n",
            "main.cu(239): warning: variable \"err\" was set but never used\n",
            "\n",
            "main.cu(241): warning: variable \"multiprocessorNum\" was declared but never referenced\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euwCiZBrz-Yk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./main 720p.png output.png 10 4 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWZHg8Rx0Wnj",
        "colab_type": "code",
        "outputId": "9593628f-267d-467d-8b9e-741b46216676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sMIMWL7JFTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}